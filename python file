!apt-get update -qq && apt-get install -y -qq tesseract-ocr libtesseract-dev poppler-utils
!pip install -q torch torchvision pytesseract pdf2image pandas pillow

# 2) Imports
import os, sys, shutil
import pandas as pd
import pytesseract
import torch
import torch.nn as nn
import torch.optim as optim
from google.colab import drive
from pdf2image import convert_from_path
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

# 3) Mount Google Drive
drive.mount('/content/drive')

# 4) Paths (adjust if needed)
BASE_DIR   = '/content/drive/MyDrive/ocr_project'
PDF_PATH   = os.path.join(BASE_DIR, 'scanned_input.pdf')  # input PDF
IMG_DIR    = os.path.join(BASE_DIR, 'train_images')      # where PDF pages become images
LABELS_CSV = os.path.join(BASE_DIR, 'labels.csv')        # will be created automatically
MODEL_PATH = os.path.join(BASE_DIR, 'crnn_model.pth')
TEST_IMG   = '/content/testdata.png'                     # upload via Files pane
CSV_OUT    = os.path.join(BASE_DIR, 'testdata_table.csv')

# 5) Clear and recreate image folder
if os.path.exists(IMG_DIR):
    shutil.rmtree(IMG_DIR)
os.makedirs(IMG_DIR, exist_ok=True)

# 6) Convert PDF pages to images
def convert_pdf_to_images(pdf_path, out_dir, dpi=150):
    pages = convert_from_path(pdf_path, dpi=dpi, fmt='png', output_folder=out_dir)
    print(f"Converted {len(pages)} pages.")
    return pages
pages = convert_pdf_to_images(PDF_PATH, IMG_DIR)

# 7) Auto-generate labels.csv from OCR if not present
if not os.path.exists(LABELS_CSV):
    records = []
    for fname in sorted(os.listdir(IMG_DIR)):
        if fname.lower().endswith('.png'):
            text = pytesseract.image_to_string(Image.open(os.path.join(IMG_DIR, fname)))
            records.append({'filename': fname, 'text': text.replace('\n', ' ').strip()})
    pd.DataFrame(records).to_csv(LABELS_CSV, index=False)
    print(f"labels.csv created with {len(records)} entries.")
else:
    print(f"Found existing labels.csv with {pd.read_csv(LABELS_CSV).shape[0]} entries.")

# 8) Dataset & DataLoader definitions
charset = list("0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-/:;.,'&?() ")
char_to_idx = {c:i+1 for i,c in enumerate(charset)}  # CTC blank=0

class OCRDataset(Dataset):
    def __init__(self, img_dir, labels_csv, transform=None):
        df = pd.read_csv(labels_csv)
        self.samples = [(os.path.join(img_dir, r['filename']), r['text']) for _, r in df.iterrows()]
        self.transform = transform
    def __len__(self): return len(self.samples)
    def __getitem__(self, idx):
        path, text = self.samples[idx]
        img = Image.open(path).convert('L')
        if self.transform: img = self.transform(img)
        target = torch.tensor([char_to_idx.get(c,0) for c in text], dtype=torch.long)
        return img, target

def collate_fn(batch):
    imgs, tgts = zip(*batch)
    imgs = torch.stack(imgs)
    lengths = torch.tensor([t.size(0) for t in tgts], dtype=torch.long)
    targets = torch.cat(tgts)
    return imgs, targets, lengths

transform = transforms.Compose([
    transforms.Resize((32,128)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])
dataset = OCRDataset(IMG_DIR, LABELS_CSV, transform)
loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)

# 9) Define CRNN model correctly with two LSTM layers
class CRNN(nn.Module):
    def __init__(self, nc=1, nclass=len(charset)+1, nh=256):
        super().__init__()
        self.cnn = nn.Sequential(
            nn.Conv2d(nc,64,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2),
            nn.Conv2d(64,128,3,1,1), nn.ReLU(), nn.MaxPool2d(2,2),
            nn.Conv2d(128,256,3,1,1), nn.ReLU(),
            nn.Conv2d(256,256,3,1,1), nn.ReLU(), nn.MaxPool2d((2,1),(2,1)),
            nn.Conv2d(256,512,3,1,1), nn.ReLU(), nn.BatchNorm2d(512),
            nn.Conv2d(512,512,3,1,1), nn.ReLU(), nn.MaxPool2d((2,1),(2,1)),
            nn.Conv2d(512,512,2,1,0), nn.ReLU()
        )
        self.rnn1 = nn.LSTM(512, nh, bidirectional=True)
        self.rnn2 = nn.LSTM(nh*2, nh, bidirectional=True)
        self.fc = nn.Linear(nh*2, nclass)

    def forward(self, x):
        conv = self.cnn(x)                      # [b, c, h=1, w]
        b, c, h, w = conv.size()
        conv = conv.squeeze(2).permute(2,0,1)   # [w, b, c]
        rec, _ = self.rnn1(conv)
        rec, _ = self.rnn2(rec)
        output = self.fc(rec)                   # [w, b, nclass]
        return output.log_softmax(2)

# 10) Train the model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = CRNN().to(device)
criterion = nn.CTCLoss(blank=0)
optimizer = optim.Adam(model.parameters(), lr=1e-3)
epochs = 5
for epoch in range(1, epochs+1):
    model.train(); total_loss = 0
    for imgs, targets, lengths in loader:
        b = imgs.size(0)
        imgs, targets = imgs.to(device), targets.to(device)
        input_lengths = torch.full((b,), 128, dtype=torch.long)
        preds = model(imgs)                     # [seq_len, b, nclass]
        loss = criterion(preds, targets, input_lengths, lengths)
        optimizer.zero_grad(); loss.backward(); optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch}/{epochs}, Loss: {total_loss/len(loader):.4f}")
# save model
torch.save(model.state_dict(), MODEL_PATH)
print(f"Model saved to {MODEL_PATH}")

# 11) Inference on test image
if not os.path.exists(TEST_IMG): sys.exit(f"Error: {TEST_IMG} not found.")
model.load_state_dict(torch.load(MODEL_PATH)); model.eval()
img = transform(Image.open(TEST_IMG).convert('L')).unsqueeze(0).to(device)
preds = model(img)
seq = preds.argmax(2).squeeze(1).permute(1,0)[0]
decoded, prev = [], 0
for idx in seq.cpu().numpy():
    if idx != prev and idx != 0:
        decoded.append(charset[idx-1])
    prev = idx
out_text = ''.join(decoded)

# 12) Save output CSV
pd.DataFrame([{'recognized_text': out_text}]).to_csv(CSV_OUT, index=False)
print(f"Inference result saved to {CSV_OUT}")

